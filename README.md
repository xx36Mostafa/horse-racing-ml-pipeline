
# ğŸ‡ Horse Racing Results Scraper & ML Dataset Builder

This project automates the extraction, cleaning, and structuring of historical horse racing results from [tab.com.au](https://tab.com.au) using custom scraping logic and machine learning-friendly formatting. It was built for predictive modeling and racing analytics using Python and custom APIs.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ extract-day.py       # API collector â€“ fetches race result URLs
â”œâ”€â”€ extract-data.py      # Data scraper â€“ extracts structured data from URLs
â”œâ”€â”€ comaine.py           # Combines monthly CSVs into one final dataset
â”œâ”€â”€ racing-apis/         # Raw JSON files of race links per day
â”œâ”€â”€ racing-data/         # Cleaned daily CSV files of race results
â””â”€â”€ final_combined_racing_data.csv  # Final merged dataset (output)
```

---

## ğŸ” Features

- âœ… **Automated Historical Scraping** with retry logic and proxies  
- ğŸ“… **Date Range Support** for fetching only required days
- ğŸ§ª **JSON to CSV Parsing** with structured formatting
- ğŸ§  Ready for **Machine Learning Training**
- ğŸ§¼ Handles:
  - Missing or malformed JSON
  - Failed API retries with logging
  - Previous runs resume without duplications

---

## ğŸš€ How It Works

### 1. Collect Race URLs by Date
**`extract-day.py`**  
Fetches race metadata & result API links from each date in a defined range.

```bash
python extract-day.py
```

Outputs JSON files in `racing-apis/YYYY-MM/`.

---

### 2. Scrape and Clean Data
**`extract-data.py`**  
Loads the race result URLs from step 1, scrapes relevant race fields (horse, jockey, barrier, trainer, odds, finish), and saves daily structured CSVs.

```bash
python extract-data.py
```

Output: Cleaned daily CSVs in `racing-data/YYYY-MM/`.

---

### 3. Combine All Monthly Files
**`comaine.py`**  
Scans the `racing-data` directory and merges all daily CSVs into a single file.

```bash
python comaine.py
```

Final dataset: `final_combined_racing_data.csv`.

---

## ğŸ“Š Example Data Columns

- `Date`
- `Track`
- `Race Number`
- `Horse`
- `Jockey`
- `Trainer`
- `Barrier`
- `SP` (Starting Price / Odds)
- `Finish Position`
- `Race Distance`
- `Class`
- `Track Condition`
- `Weather`
- `Total Runners`

---

## ğŸ”§ Requirements

- Python 3.9+
- `pandas`
- `tls-client`  
  > Install using unofficial methods or custom wheels due to its non-standard distribution.

---

## âš ï¸ Notes

- This script respects retry logic and error recovery.
- Proxy support is included and can be modified in `extract-day.py`.
- All scrapers are built with ethical scraping principles, targeting publicly available APIs.

---

## ğŸ§  Future Work

- Model training notebooks for predicting finish positions.
- Exploratory Data Analysis (EDA) and feature engineering.
- Deployment-ready race predictor.

---

## ğŸ™‹â€â™‚ï¸ Author

**Mostafa Nasser**  
Specialist in scraping, automation, and ML pipelines  
ğŸ”— [GitHub](https://github.com/xx36Mostafa)


---

## ğŸ“¦ Model Note

âš ï¸ **Pretrained model files were not uploaded due to file size limitations.**  
To use the full pipeline, please run the main notebook (`main.ipynb`) locally. It will automatically **retrain the model from scratch** using the combined dataset (`final_combined_racing_data.csv`).

